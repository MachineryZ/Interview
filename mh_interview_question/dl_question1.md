1. 在 deep learning 里，某些领域中，网络的 inference 速度非常重要。请你简述一篇你知道的加速神经网络 inference 速度的方法。
2. 如果你对这部分不太了解，那么给你一个矩阵计算为 y = Wx，请你想一想如果得到一个近似的 W‘ 来使得输出的 y’ 和我们原始 W 对应的 y尽可能地“像”。同理，对于请你想一种方法，对卷积操作 y = W * x，得到一个近似的 W‘。

（提示：可以往这几个方向来想：矩阵分解、数值计算简化、把问题转化成带约束的凸优化问题，等等）

（对于矩阵分解方法，可以尝试把 W 分解成若干小的、稀疏的子矩阵，然后再在这些子矩阵中做文章）

（对于数据计算简化方法，一般存储矩阵的方式都是 float32，我们可以试试看有什么更快速地计算的存储方式之类的）

3. 第一问和第二问选择一问回答即可。但需要给一个：**详细的算法流程描述**、**近似方法的理论支持**、相比原始的矩阵乘法或者卷积操作简化了哪些部分。
4. 言之有理，自洽即可